{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangoml/networkx-adapter/blob/master/examples/ITSM_ArangoDB_Adapter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjUp8oZA_0EL"
   },
   "source": [
    "# Predicting IT Service Ticket Reassingnment Using RGCN (DGL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6qWopH1_0EN"
   },
   "source": [
    "This notebook provides the details of applying a __Graph Convolutional Network(GCN)__ to predict if an IT service ticket will be reassigned. The workflow associated with ticket resolution has a convinient graph representation. The raw data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log) is loaded into ArangoDB using the [ITSM_data_loader python file](files/ITSM_data_loader.py). The [DGL](https://github.com/dmlc/dgl) library is used to create the __GCN__ model that is used to predict ticket reassignment. The graph associated with this prediction task is _heterogeneous_. This means that the graph has multiple types of vertices. In this example, the _incident_ (for which the ticket is created), the _support_org_ (the organization resolving the ticket), the _customer_ (who opened the ticket) and the _vendor_ (if the ticket is associated with an external product) are the different vertices in the graph (see [working with heterographs in DGL](https://docs.dgl.ai/en/0.4.x/tutorials/hetero/1_basics.html) for more details). Each of these vertices has attributes that are utilized in predicting the _reassignment_ status of a ticket. In this work, both the graph structure associated with a particular _incident_ and the properties associated with the vertices of the graph are used in the __GCN__. In particular, the semi-supervised model described in [\"working with heterographs in DGL\"](https://docs.dgl.ai/en/0.4.x/tutorials/hetero/1_basics.html), based on work by [Kipf et al.,](https://arxiv.org/abs/1703.06103) will be used here. The details of the implementaion are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6LQVNyO_0EQ"
   },
   "source": [
    "## Install Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FF_RsnbzZsAM"
   },
   "outputs": [],
   "source": [
    "%%capture cap_out --no-stderr\n",
    "!git clone -b master https://github.com/arangoml/networkx-adapter.git\n",
    "!rsync - av networkx-adapter/examples / . / --exclude = .git\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib\n",
    "!pip install --index-url https://test.pypi.org/simple/ adbnx-adapter==0.0.0.2.5.3\n",
    "!pip3 install pyarango\n",
    "!pip3 install python-arango\n",
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly7pC2qEAjdL"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './networkx-adapter/examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-001c3dc5fc91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./networkx-adapter/examples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './networkx-adapter/examples'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('./networkx-adapter/examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50Xg1Wz1_0Eb"
   },
   "source": [
    "## Obtain an Oasis Connection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "punGc278_0Ec"
   },
   "source": [
    "Oasis is the __ArangoDB__ managed service database offering. We will use __Oasis__ for this work. This permits us to use __ArangoDB__ without worrying about the details of installation and set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhIdp2rNaos7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Unable to establish connection, perhaps arango is not running.\n",
      "===\n",
      "Credentials expired.\n",
      "Requesting new temp credentials.\n",
      "Temp database ready to use.\n",
      "\n",
      "https://d383fa0b596a.arangodb.cloud:8529\n",
      "Username: TUT92ui1mkp7eeoxkdqqlvmwg\n",
      "Password: TUT1gp8txohyjcw6mzhmqlafq\n",
      "Database: TUTduy9uz762uta7iggbfhkck\n"
     ]
    }
   ],
   "source": [
    "import oasis\n",
    "con = oasis.getTempCredentials()\n",
    "\n",
    "print()\n",
    "print(\"https://{}:{}\".format(con[\"hostname\"], con[\"port\"]))\n",
    "print(\"Username: \" + con[\"username\"])\n",
    "print(\"Password: \" + con[\"password\"])\n",
    "print(\"Database: \" + con[\"dbName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWWsUIV0_0Ei"
   },
   "source": [
    "## Load the Data into Oasis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HoUDu8R_0Ej"
   },
   "source": [
    "The _arangorestore_ utility is used to load the database into the __Oasis__ instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5Q1aESiatNB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m2020-06-22T12:20:57Z [15150] INFO [05c30] {restore} Connected to ArangoDB 'http+ssl://d383fa0b596a.arangodb.cloud:8529'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:20:59Z [15150] INFO [abeb4] {restore} Database name in source dump is 'TUThjyjglmb376tll56bgsvo'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:20:59Z [15150] INFO [9b414] {restore} # Re-creating document collection 'customer'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:20:59Z [15150] INFO [9b414] {restore} # Re-creating document collection 'incident'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:00Z [15150] INFO [9b414] {restore} # Re-creating document collection 'support_org'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:00Z [15150] INFO [9b414] {restore} # Re-creating document collection 'vendor'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:01Z [15150] INFO [9b414] {restore} # Re-creating edge collection 'incident_customer'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:01Z [15150] INFO [9b414] {restore} # Re-creating edge collection 'incident_support_org'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:02Z [15150] INFO [9b414] {restore} # Re-creating edge collection 'incident_vendor'...\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:02Z [15150] INFO [6d69f] {restore} # Dispatched 7 job(s), using 2 worker(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:02Z [15150] INFO [94913] {restore} # Loading data into document collection 'customer', data size: 597532 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:02Z [15150] INFO [94913] {restore} # Loading data into document collection 'incident', data size: 976791 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:06Z [15150] INFO [6ae09] {restore} # Successfully restored document collection 'customer'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:06Z [15150] INFO [94913] {restore} # Loading data into document collection 'support_org', data size: 642293 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:07Z [15150] INFO [75e65] {restore} # Current restore progress: restored 1 of 7 collection(s), read 18059550 byte(s) from datafiles, sent 3 data batch(es) of 4413614 byte(s) total size, queued jobs: 4, workers: 2\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:10Z [15150] INFO [6ae09] {restore} # Successfully restored document collection 'support_org'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:10Z [15150] INFO [94913] {restore} # Loading data into document collection 'vendor', data size: 568543 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:11Z [15150] INFO [69a73] {restore} # Still loading data into document collection 'incident', 12534592 byte(s) restored\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:11Z [15150] INFO [6ae09] {restore} # Successfully restored document collection 'incident'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:11Z [15150] INFO [94913] {restore} # Loading data into edge collection 'incident_customer', data size: 1050511 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:12Z [15150] INFO [75e65] {restore} # Current restore progress: restored 3 of 7 collection(s), read 33606716 byte(s) from datafiles, sent 6 data batch(es) of 22205531 byte(s) total size, queued jobs: 2, workers: 2\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:15Z [15150] INFO [6ae09] {restore} # Successfully restored document collection 'vendor'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:15Z [15150] INFO [94913] {restore} # Loading data into edge collection 'incident_support_org', data size: 1058346 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:17Z [15150] INFO [75e65] {restore} # Current restore progress: restored 4 of 7 collection(s), read 41240741 byte(s) from datafiles, sent 7 data batch(es) of 26346910 byte(s) total size, queued jobs: 1, workers: 2\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:18Z [15150] INFO [6ae09] {restore} # Successfully restored edge collection 'incident_customer'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:18Z [15150] INFO [94913] {restore} # Loading data into edge collection 'incident_vendor', data size: 1048582 byte(s)\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:22Z [15150] INFO [75e65] {restore} # Current restore progress: restored 5 of 7 collection(s), read 48251720 byte(s) from datafiles, sent 8 data batch(es) of 33606711 byte(s) total size, queued jobs: 0, workers: 2\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:22Z [15150] INFO [6ae09] {restore} # Successfully restored edge collection 'incident_support_org'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:27Z [15150] INFO [75e65] {restore} # Current restore progress: restored 6 of 7 collection(s), read 48251720 byte(s) from datafiles, sent 8 data batch(es) of 41240735 byte(s) total size, queued jobs: 0, workers: 2\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:29Z [15150] INFO [6ae09] {restore} # Successfully restored edge collection 'incident_vendor'\n",
      "\u001b[0m\u001b[0m2020-06-22T12:21:29Z [15150] INFO [a66e1] {restore} Processed 7 collection(s) in 33.749267 s, read 48251720 byte(s) from datafiles, sent 8 data batch(es) of 48251713 byte(s) total size\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!./tools/arangorestore -c none --server.endpoint http+ssl://{con[\"hostname\"]}:{con[\"port\"]} --server.username {con[\"username\"]} --server.database {con[\"dbName\"]} --server.password {con[\"password\"]} --default-replication-factor 3  --input-directory \"data/dgl_data_dump\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqwkRxVx_0Eo"
   },
   "source": [
    "## Create the ArangoDB DGL Adapter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4c-5Cpl_0Ep"
   },
   "source": [
    "The __ArangoDB DGL Adapter__ will create a __dgl heterograph__ from __ArangoDB__. To create the __dgl heterograph__ we will need to provide a description of the graph that we would like to create. This is done by describing the vertices and edges of the graph using a _dictionary_ data structure. The details of the vertices and edges for this example are shown below. The __ArangoDB DGL Adapter__ specifies the details of the heterograph to __DGL__ using __Networkx__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5C-NW4amZ815"
   },
   "outputs": [],
   "source": [
    "vcols = {\"incident\": {\"D_sys_mod_count\", \"D_sys_mod_count\", \"D_reopen_count\", \"urgency\", \"incident_state\",\n",
    "                      \"u_symptom\", \"impact\", \"contact_type\", \"u_priority_confirmation\", \"cmdb_ci\",\n",
    "                      \"rfc\", \"problem_id\", \"caused_by\", \"location\", \"knowledge\", \"resolved_by\",\n",
    "                      \"subcategory\", \"active\", \"category\", \"priority\", \"reassigned\", \"node_id\"},\n",
    "         \"support_org\": {\"assigned_to\", \"assignment_group\", \"node_id\"},\n",
    "         \"customer\": {\"opened_by\", \"node_id\"},\n",
    "         \"vendor\": {\"vendor\", \"node_id\"}}\n",
    "ecols = {\"incident_support_org\": {\"_from\", \"_to\"}, \"incident_customer\": {\"_from\", \"_to\"},\n",
    "         \"incident_vendor\": {\"_from\", \"_to\"}}\n",
    "\n",
    "itsm_attributes = {'vertexCollections': vcols, 'edgeCollections': ecols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8KCUbNi_0Eu"
   },
   "source": [
    "After the graph structure has been defined, instantiate the _DGLArangoDB_Networkx_Adapter_ with connection and create the __dgl graph__ as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qACbcQBbLEx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from adbnx_adapter.dgl_arangoDB_networkx_adapter import DGLArangoDB_Networkx_Adapter\n",
    "itsmg = DGLArangoDB_Networkx_Adapter(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBIgn6fGbPo1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DGL graph...\n",
      "Loading edge data...\n",
      "Loading vertex data...\n",
      "Creating DGL Heterograph...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "g, labels = itsmg.create_dgl_graph(\n",
    "    graph_name='ITSMGraph',  graph_attributes=itsm_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvY1SS3u_0E3"
   },
   "source": [
    "## Visually Inspect the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KL6fN4wbfW3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "nx.draw_networkx(g.metagraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uMb3qm6_0E8"
   },
   "source": [
    "## Define the GCN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTqlOrYA_0E8"
   },
   "source": [
    "_Note_ :Node attributes have been discretized. An embedding layer is used to generate feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyDWiVL8bSny"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "class HeteroRGCNLayer1(nn.Module):\n",
    "    EMBED_SIZE = 64\n",
    "    VOCAB_SIZE = 2386\n",
    "\n",
    "    def __init__(self, hidden_size, G):\n",
    "        super(HeteroRGCNLayer1, self).__init__()\n",
    "        # Need an embedding layer for each node feature\n",
    "        self.node_embeddings = {}\n",
    "        #self.dropouts = {}\n",
    "        for ntype in G.ntypes:\n",
    "            # create an embedding for each feature of a node\n",
    "            self.node_embeddings[ntype] = {}\n",
    "            num_node_features = G.node_attr_schemes(ntype)['f'].shape[0]\n",
    "            for feature in range(num_node_features):\n",
    "                self.node_embeddings[ntype][feature] = nn.Embedding(\n",
    "                    self.VOCAB_SIZE, self.EMBED_SIZE)\n",
    "            #self.dropouts[ntype] = nn.Dropout()\n",
    "        # for name in etypes:\n",
    "        module_layers = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
    "            module_layers[etype] = nn.Linear(\n",
    "                num_features * self.EMBED_SIZE, hidden_size)\n",
    "        self.weight = nn.ModuleDict(module_layers)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, G):\n",
    "\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # for each node compute the embedding and store it in the graph\n",
    "            # iterate over the features of each node and compute the embedding\n",
    "            the_node_embedding = self.node_embeddings[srctype]\n",
    "            node_feature_embeddings = []\n",
    "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
    "            for feature in range(num_features):\n",
    "                feature_embedding_layer = the_node_embedding[feature]\n",
    "                node_feature_embeddings.append(feature_embedding_layer(\n",
    "                    G.nodes[srctype].data['f'][:, feature]))\n",
    "            comp_node_embedding = torch.cat(node_feature_embeddings, 1)\n",
    "            G.nodes[srctype].data['E'] = comp_node_embedding\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](G.nodes[srctype].data['E'])\n",
    "            #Wh = torch.sum(Wh, dim = 1)\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return G\n",
    "        return {ntype: G.nodes[ntype].data['h'] for ntype in G.ntypes}\n",
    "\n",
    "\n",
    "class HeteroRGCNLayer2(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer2, self).__init__()\n",
    "        # W_r for each relation\n",
    "\n",
    "        self.weight = nn.ModuleDict({\n",
    "            name: nn.Linear(in_size, out_size) for name in etypes\n",
    "        })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh2_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh2_%s' %\n",
    "                                      etype, 'm'), fn.mean('m', 'h2'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return G\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype: G.nodes[ntype].data['h2'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mjsfj08cboEx"
   },
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer1(hidden_size, G)\n",
    "        self.layer2 = HeteroRGCNLayer2(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "\n",
    "        h_dict = self.layer1(G)\n",
    "        h_dict = {k: F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "\n",
    "        # get paper logits\n",
    "\n",
    "        return h_dict['incident']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqMjZoSO_0FE"
   },
   "source": [
    "## Create Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2YZAGfgbsSy"
   },
   "outputs": [],
   "source": [
    "training_mask = np.random.rand(len(labels)) <= 0.8\n",
    "train_idx = [i for i in range(len(labels)) if training_mask[i]]\n",
    "test_idx = [i for i in range(len(labels)) if not training_mask[i]]\n",
    "train_idx = torch.tensor(train_idx).long()\n",
    "test_idx = torch.tensor(test_idx).long()\n",
    "labels = torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJIloQV-_0FI"
   },
   "source": [
    "## Train and Evaluate the Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XH-d0z3ibzJ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.58 µs\n",
      "Loss 0.7341, training accuracy 0.4717, test accuracy 0.4774\n",
      "Loss 0.5801, training accuracy 0.6409, test accuracy 0.6360\n",
      "Loss 0.4765, training accuracy 0.7810, test accuracy 0.7676\n",
      "Loss 0.4400, training accuracy 0.7989, test accuracy 0.7901\n",
      "Loss 0.4119, training accuracy 0.8137, test accuracy 0.8074\n",
      "Loss 0.3904, training accuracy 0.8236, test accuracy 0.8186\n",
      "Loss 0.3759, training accuracy 0.8296, test accuracy 0.8231\n",
      "Loss 0.3638, training accuracy 0.8382, test accuracy 0.8314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4417f30b68d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# The loss is computed only for labeled nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpred_trng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Create the model. The output has three logits for three classes.\n",
    "\n",
    "\n",
    "#model = HeteroRGCN(G, 512,64, 2)\n",
    "\n",
    "#opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "# ,\n",
    "model = HeteroRGCN(g, 32, 2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    opt.zero_grad()\n",
    "    logits = model(g)\n",
    "    # The loss is computed only for labeled nodes.\n",
    "    loss = loss_fn(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    pred_trng = torch.argmax(logits[train_idx], dim=1)\n",
    "    res_trng = pred_trng == labels[train_idx]\n",
    "    trng_acc = torch.sum(res_trng).item()/labels[train_idx].shape[0]\n",
    "\n",
    "    pred_test = torch.argmax(logits[test_idx], dim=1)\n",
    "    res_test = pred_test == labels[test_idx]\n",
    "    test_acc = torch.sum(res_test).item()/labels[test_idx].shape[0]\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Loss %.4f, training accuracy %.4f, test accuracy %.4f' %\n",
    "              (loss.item(), trng_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_B6fTCvt_0FM"
   },
   "source": [
    "## Note\n",
    "The implementation comes with a database dump required for this exercise. If there is a need to recreate the dump, remove the existing creds.dat file and create an empty creds.dat file. The $\\texttt{itsm_data_load_driver}$ can then be used to load the data to an __Oasis__ instance. The data load procedure can take about $15$ minutes to complete. Once, the data load is done, the _arangodump_ utility can be used to create a dump of the loaded data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZucEAm4_0FM"
   },
   "outputs": [],
   "source": [
    "!rm creds.dat\n",
    "!touch creds.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsJyZCgz_0FQ"
   },
   "outputs": [],
   "source": [
    "from itsm_data_load_driver import load_ITSM_data_to_ArangoDB\n",
    "itsmdl = load_ITSM_data_to_ArangoDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bto7Q0qa_0FT"
   },
   "outputs": [],
   "source": [
    "#arangodump --server.endpoint <put server address eg., http+ssl://5904e8d8a65f.arangodb.cloud:8529> --server.username <put user name>  --server.database <put dbName> --server.password <put passwd> --output-directory dgl_data_dump\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ITSM_ArangoDB_Adapter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
